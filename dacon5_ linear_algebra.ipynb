{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a484d54",
   "metadata": {},
   "source": [
    "# Stage 5. Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25732767",
   "metadata": {},
   "source": [
    "# 1. 곱셈 연산\n",
    "## 1.1 Vector 곱셈 (점곱, Dot Product)\n",
    "Dot Product는 두 Vector 간의 연산으로, 각 Vector의 상응하는 성분들을 곱한 뒤 그 결과들을 모두 더해 하나의 Scalar 값으로 반환합니다.  \n",
    "이 연산은 두 Vector의 내적을 계산하는 것과 동일합니다.\n",
    "\n",
    "Vector의 곱셈은 다음과 같이 계산합니다.\n",
    "\n",
    "$$\n",
    "a = \\begin{bmatrix}\n",
    "a_1 \\\\\n",
    "a_2 \\\\\n",
    "\\vdots \\\\\n",
    "a_n\n",
    "\\end{bmatrix}, \\quad\n",
    "b = \\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "\\vdots \\\\\n",
    "b_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a \\cdot b = \\sum_{i=1}^{n} a_i b_i = a_1 b_1 + a_2 b_2 + \\cdots + a_n b_n\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bf15ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터의 내적 결과: tensor(32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Vector 정의\n",
    "vector1 = torch.tensor([1, 2, 3])\n",
    "vector2 = torch.tensor([4, 5, 6])\n",
    "\n",
    "# Vector의 내적 계산\n",
    "dot_product = vector1 @ vector2\n",
    "# 또는 torch.dot(vector1, vector2) 로 내적을 계산할 수 있다.\n",
    "\n",
    "print(\"벡터의 내적 결과:\", dot_product) \n",
    "# 출력이 32인 이유: 1*4 + 2*5 + 3*6 = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985ed06b",
   "metadata": {},
   "source": [
    "## 1.2 행렬의 곱셈\n",
    "\n",
    "행렬 $A$와 행렬 $B$의 곱셈 $AB$를 고려해봅시다.  \n",
    "$A$가 $m \\times n$ 행렬이고 $B$가 $n \\times p$ 행렬일 때,  \n",
    "두 행렬의 곱은 $m \\times p$ 행렬 $C$가 됩니다.  \n",
    "\n",
    "행렬 $C$의 각 요소 $c_{ij}$는 다음과 같이 계산됩니다.\n",
    "\n",
    "$$\n",
    "c_{ij} = \\sum_{k=1}^{n} a_{ik} \\cdot b_{kj}\n",
    "$$\n",
    "\n",
    "구체적으로는 아래와 같이 계산하면 됩니다.\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "a_{11} & a_{12} & a_{13} \\\\\n",
    "a_{21} & a_{22} & a_{23}\n",
    "\\end{bmatrix}, \\quad\n",
    "B = \\begin{bmatrix}\n",
    "b_{11} & b_{12} \\\\\n",
    "b_{21} & b_{22} \\\\\n",
    "b_{31} & b_{32}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "이때, 행렬 곱은\n",
    "\n",
    "$$\n",
    "AB = \\begin{bmatrix}\n",
    "a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} & a_{11}b_{12} + a_{12}b_{22} + a_{13}b_{32} \\\\\n",
    "a_{21}b_{11} + a_{22}b_{21} + a_{23}b_{31} & a_{21}b_{12} + a_{22}b_{22} + a_{23}b_{32}\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffef6338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 matrix1:\n",
      " tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "행렬 matrix2:\n",
      " tensor([[5, 6],\n",
      "        [7, 8]])\n",
      "matrix1와 matrix2의 곱 mul_matrix:\n",
      " tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "# 두 개의 2x2 행렬을 정의합니다.\n",
    "matrix1 = torch.tensor([[1, 2], [3, 4]])\n",
    "matrix2 = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# 행렬 곱셈 연산을 수행합니다.\n",
    "mul_matrix = torch.matmul(matrix1, matrix2)\n",
    "\n",
    "print(\"행렬 matrix1:\\n\", matrix1)\n",
    "print(\"행렬 matrix2:\\n\", matrix2)\n",
    "print(\"matrix1와 matrix2의 곱 mul_matrix:\\n\", mul_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1132f4d",
   "metadata": {},
   "source": [
    "# 2. Determinant (행렬 식)\n",
    "### 행렬식이란\n",
    "행렬식의 값은 행렬이 **역행렬**을 가지는지 여부를 결정합니다. 행렬식이 0이 아니면 행렬은 역행렬을 가지며, 행렬식이 0이면 행렬은 역행렬을 가지지 않습니다.\\\n",
    "\\\n",
    "또한, 행렬식은 모든 열(또는 행)이 생성하는 공간의 부피를 나타내며, 행렬이 선형 변환을 수행할 때 공간이 얼마나 확장 또는 축소되는지를 나타냅니다. 이는 행렬이 선형 독립인 열(또는 행)을 가지고 있는지 여부를 판단하는 데도 사용됩니다.\\\n",
    "\\\n",
    "PyTorch에서는 torch.linalg.det() 함수를 사용하여 주어진 행렬의 행렬식을 계산합니다.\n",
    "\n",
    "### 행렬식\n",
    "$2\\times2$ 행렬의 경우, 행렬식은 다음과 같습니다.\n",
    "$$\n",
    "\\det(A) = ad - bc\n",
    "$$\n",
    "그 외 일반적인 행렬의 행렬식은 다음과 같습니다.\n",
    "$$\n",
    "\\det(A) = \\sum_{j=1}^{n} (-1)^{i+j} a_{ij} \\cdot \\det(A_{ij})\n",
    "$$\n",
    "$a_{ij}$는 A의 i행 j열에 위치한요소. $A_{ij}$는 $a_{ij}$를 제외한 행렬에서 i행과 j열을 제거하여 얻은 부분 행렬\n",
    "\n",
    "## 2.1. 행렬식 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b84b209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 행렬의 행렬식: 10.000000953674316\n",
      "직접 계산:  10\n"
     ]
    }
   ],
   "source": [
    "matrix_A = torch.tensor([[4, 7], [2, 6]], dtype=torch.float32)\n",
    "\n",
    "# 행렬식 계산\n",
    "det_A = torch.linalg.det(matrix_A)\n",
    "\n",
    "print(f\"A 행렬의 행렬식: {det_A}\")\n",
    "print('직접 계산: ', 4*6 - 7*2)  # 직접 계산: 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17782e90",
   "metadata": {},
   "source": [
    "## 2.2. 행렬식 예제 2\n",
    "- 행렬식이 0인 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1a9811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B 행렬의 행렬식: 0.0\n"
     ]
    }
   ],
   "source": [
    "# 3x3 행렬 정의\n",
    "matrix_B = torch.tensor(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]], dtype=torch.float32)\n",
    "\n",
    "# 행렬식 계산\n",
    "det_B = torch.linalg.det(matrix_B)\n",
    "print(f\"B 행렬의 행렬식: {det_B}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3179e2f8",
   "metadata": {},
   "source": [
    "# 3. 역행렬\n",
    "Inverse Matrix (역행렬)은 선형 대수학에서 주어진 행렬 A에 대해, A와 곱했을 때 항등 행렬 I를 생성하는 행렬을 말합니다.\\\n",
    "\\\n",
    "식으로 표현하면 아래와 같습니다.\n",
    "$$\n",
    "A \\times A^{-1} = A^{-1} \\times A = I\n",
    "$$\n",
    "항등 행렬 I는 모든 대각선 상의 원소가 1이고, 그 외의 원소는 모두 0인 행렬을 의미합니다.\\\n",
    "\\\n",
    "항등 행렬을 식으로 표현하면 아래와 같습니다.\n",
    "$$\n",
    "I =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & \\cdots & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "## 3.1. 역행렬 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a76e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix_A 행렬:\n",
      " tensor([[4., 7.],\n",
      "        [2., 6.]])\n",
      "matrix_A의 역행렬:\n",
      " tensor([[ 0.6000, -0.7000],\n",
      "        [-0.2000,  0.4000]])\n"
     ]
    }
   ],
   "source": [
    "# 가역적인 2x2 행렬 정의\n",
    "matrix_A = torch.tensor([[4.0, 7.0], [2.0, 6.0]])\n",
    "\n",
    "# 역행렬 계산\n",
    "matrix_inv = torch.linalg.inv(matrix_A)\n",
    "\n",
    "print(\"matrix_A 행렬:\\n\", matrix_A)\n",
    "print(\"matrix_A의 역행렬:\\n\", matrix_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe990ea",
   "metadata": {},
   "source": [
    "## 3.2. 역행렬 식 확인해보기 (1)\n",
    "$A \\times A^{-1} = I$ 식이 맞는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a193422b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A x A-1 가 항등 행렬인지 확인해 봅시다.\n",
    "torch.matmul(matrix_A, matrix_inv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182c7dad",
   "metadata": {},
   "source": [
    "## 3.3. 역행렬 식 확인해보기 (2)\n",
    "$A^{-1} \\times A = I$ 식이 맞는지 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5adc5c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A-1 x A가 항등 행렬인지 확인해 봅시다.\n",
    "torch.matmul(matrix_inv, matrix_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe53ecd",
   "metadata": {},
   "source": [
    "## 3.4. 행렬식이 0일 때, 역행렬 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5138b81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix 행렬의 행렬식: 0.0\n"
     ]
    }
   ],
   "source": [
    "matrix = torch.tensor(\n",
    "    [[1, 2, 3],\n",
    "     [4, 5, 6],\n",
    "     [7, 8, 9]], dtype=torch.float32)\n",
    "\n",
    "det = torch.linalg.det(matrix)\n",
    "print(f\"matrix 행렬의 행렬식: {det}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cd5c685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linalg.inv: The diagonal element 3 is zero, the inversion could not be completed because the input matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.linalg.inv(matrix)\n",
    "except Exception as e:\n",
    "    print(e) # 행렬식이 0일 때, 역행렬을 구하면 에러가 발생하는 것을 확인할 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66367d3",
   "metadata": {},
   "source": [
    "# 4. Trace\n",
    "### Trace란?\n",
    "Trace는 선형대수학에서 사용되는 용어로, 주로 정사각형 행렬에 대해 정의됩니다. Trace는 행렬의 diagonal(주대각선) 상의 모든 원소의 합으로 계산됩니다. 즉, 행렬 A의 Trace는 A의 i번째 행과 i번째 열이 만나는 위치의 원소들 $a_{ii}$의 합으로 표현됩니다.\\\n",
    "수학적으로는 다음과 같이 표현됩니다.\n",
    "$$\n",
    "Tr(A) = \\sum_{i=1}^{n}a_{ii}\n",
    "$$\n",
    "torch.trace() 함수를 이용하면 Trace 연산을 수행할 수 있습니다.\n",
    "### 주의할 점\n",
    "- torch.trace() 함수는 주로 2D Tensor에 사용됩니다. 만약 더 높은 차원의 Tensor를 입력으로 사용한다면, 함수는 내부적으로 Tensor의 마지막 두 차원에 대해 Trace 연산을 수행합니다.\n",
    "\n",
    "- 행렬의 Trace는 행렬이 정사각형일 때 가장 의미가 있습니다. 비정사각형 행렬의 경우에도 대각선 원소들의 합은 계산되지만, Trace가 가지는 선형대수학적 의미는 다를 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a26a4247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 행렬의 Trace: 15.0\n"
     ]
    }
   ],
   "source": [
    "# 정사각 행렬 정의\n",
    "A = torch. tensor([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]], dtype=torch.float)\n",
    "\n",
    "# 행렬의 트레이스 계산\n",
    "trace_A = torch.trace(A)\n",
    "print(f\"A 행렬의 Trace: {trace_A}\")  # 출력: 15.0 (1 + 5 + 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc6abfa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
